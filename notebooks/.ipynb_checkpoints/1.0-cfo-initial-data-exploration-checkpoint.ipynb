{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46c3127c",
   "metadata": {},
   "source": [
    "# 0.0 IMPORTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a60ce4",
   "metadata": {},
   "source": [
    "## NOTES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fc7122",
   "metadata": {},
   "source": [
    "**import warnings**: used to omit the warnings in the code\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "**import ipywidgets as widgets**: Widgets are eventful python objects that have a representation in the browser, often as a control like a slider, textbox, etc (ipython.org)\n",
    "\n",
    "**import seaborn as sns**: Seaborn is a Python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics. (pydata.org)\n",
    "\n",
    "**import plotly.express as px**: The plotly.express module (usually imported as px) contains functions that can create entire figures at once, and is referred to as Plotly Express or PX. (plotly.com)\n",
    "\n",
    "**import pandas as pd**: pandas is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool (pydata.org)\n",
    "\n",
    "**import numpy as np**: It is a Python library that provides a multidimensional array object, various derived objects (such as masked arrays and matrices), and an assortment of routines for fast operations on arrays, including mathematical, logical, shape manipulation, sorting, selecting, I/O, discrete Fourier transforms, basic linear algebra, basic statistical operations, random simulation and much more. (numpy.org)\n",
    "\n",
    "**from matplotlib import pyplot as plt**: Matplotlib is a comprehensive library for creating static, animated, and interactive visualizations in Python (matplotlib.org)\n",
    "\n",
    "**from ipywidgets import fixed, interact, interactive, fixed, interact_manual**\n",
    "\n",
    "**from geopy.geocoders import Nominatim**: geopy is a Python client for several popular geocoding web services (pypi.org). Nominatim uses OpenStreetMap data to find locations on Earth by name and address (geocoding). It can also do the reverse, find an address for any location on the planet (nominatim.org).  Each geolocation service you might use, such as Google Maps, Bing Maps, or Nominatim, has its own class in geopy.geocoders abstracting the serviceâ€™s API. Geocoders each define at least a geocode method, for resolving a location from a string, and may define a reverse method, which resolves a pair of coordinates to an address. Each Geocoder accepts any credentials or settings needed to interact with its service, e.g., an API key or locale, during its initialization.\n",
    "\n",
    "**from tabulate import tabulate**: Pretty-print tabular data in Python, a library and a command-line utility (pypi.org)\n",
    "\n",
    "**from matplotlib import gridspec**: A grid layout to place subplots within a figure (matplotlib.org)\n",
    "\n",
    "**from IPython.display import Image**: Public API for display tools in IPython (pypi.org)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5e2e81",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43a162c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T00:46:47.739879Z",
     "start_time": "2022-02-23T00:46:47.719187Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import ipywidgets     as widgets\n",
    "import seaborn        as sns\n",
    "import plotly.express as px\n",
    "\n",
    "import pandas         as pd\n",
    "import numpy          as np\n",
    "\n",
    "from matplotlib       import pyplot    as plt\n",
    "\n",
    "from ipywidgets       import fixed,interact, interactive, fixed, interact_manual\n",
    "from geopy.geocoders  import Nominatim\n",
    "from tabulate         import tabulate\n",
    "from matplotlib       import gridspec\n",
    "from IPython.display  import Image \n",
    "from pathlib          import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9bd10a",
   "metadata": {},
   "source": [
    "## 0.1 Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78fcb7f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T00:46:47.810263Z",
     "start_time": "2022-02-23T00:46:47.756646Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "\n",
    "def jupyter_settings():\n",
    "    %matplotlib inline\n",
    "    %pylab inline\n",
    "    \n",
    "    plt.style.use('bmh')\n",
    "    plt.rcParams['figure.figsize'] = [25, 12]\n",
    "    plt.rcParams['font.size'] = 24\n",
    "    \n",
    "    sns.set()\n",
    "\n",
    "jupyter_settings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6d0bdc",
   "metadata": {},
   "source": [
    "# 1.0 DATA DESCRIPTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcdddd04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T00:46:48.815003Z",
     "start_time": "2022-02-23T00:46:47.821103Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/work/Documents/repos/python_zero_ao_ds/data/raw/kc_house_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df1 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/work/Documents/repos/python_zero_ao_ds/data/raw/kc_house_data.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/envs/pythonzeroaods/lib/python3.8/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/envs/pythonzeroaods/lib/python3.8/site-packages/pandas/io/parsers/readers.py:586\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    571\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    572\u001b[0m     dialect,\n\u001b[1;32m    573\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    582\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    583\u001b[0m )\n\u001b[1;32m    584\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 586\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/envs/pythonzeroaods/lib/python3.8/site-packages/pandas/io/parsers/readers.py:482\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    479\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    481\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 482\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    485\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/envs/pythonzeroaods/lib/python3.8/site-packages/pandas/io/parsers/readers.py:811\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwds:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 811\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/envs/pythonzeroaods/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1040\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1036\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1037\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown engine: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mengine\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (valid options are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmapping\u001b[38;5;241m.\u001b[39mkeys()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1038\u001b[0m     )\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;66;03m# error: Too many arguments for \"ParserBase\"\u001b[39;00m\n\u001b[0;32m-> 1040\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/envs/pythonzeroaods/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py:51\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     48\u001b[0m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musecols\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39musecols\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# open handles\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open_handles\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Have to pass int, would break tests using TextReader directly otherwise :(\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/envs/pythonzeroaods/lib/python3.8/site-packages/pandas/io/parsers/base_parser.py:222\u001b[0m, in \u001b[0;36mParserBase._open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_handles\u001b[39m(\u001b[38;5;28mself\u001b[39m, src: FilePathOrBuffer, kwds: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;124;03m    Let the readers open IOHandles after they are done with their potential raises.\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 222\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/envs/pythonzeroaods/lib/python3.8/site-packages/pandas/io/common.py:702\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    698\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    701\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 702\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    710\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    711\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/work/Documents/repos/python_zero_ao_ds/data/raw/kc_house_data.csv'"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(Path(\"/home/work/Documents/repos/python_zero_ao_ds_github/data/kc_house_data.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5069997",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T00:46:48.854651Z",
     "start_time": "2022-02-23T00:46:48.854482Z"
    }
   },
   "outputs": [],
   "source": [
    "df1.loc[df1.duplicated(subset='id')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddfc354",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T00:46:48.867292Z",
     "start_time": "2022-02-23T00:46:48.867128Z"
    }
   },
   "outputs": [],
   "source": [
    "df1 = df1.drop_duplicates(subset='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a4647b",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 1.1 Data Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21088c9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T00:46:48.878056Z",
     "start_time": "2022-02-23T00:46:48.877681Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f'Number of rows: {df1.shape[0]}')\n",
    "print(f'Number of columns: {df1.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57bdffa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T00:46:48.890400Z",
     "start_time": "2022-02-23T00:46:48.890252Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabfeb03",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 1.2 Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3897a92b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T00:46:48.907206Z",
     "start_time": "2022-02-23T00:46:48.907055Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(df1.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abe432e",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 1.3 Check NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c81460",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T00:46:48.918249Z",
     "start_time": "2022-02-23T00:46:48.918075Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df1.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdecb0fb",
   "metadata": {},
   "source": [
    "## 1.4 Change Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b8b5c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T00:46:48.929653Z",
     "start_time": "2022-02-23T00:46:48.929501Z"
    }
   },
   "outputs": [],
   "source": [
    "df1['date'] = pd.to_datetime(df1['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7a229f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T00:46:48.941175Z",
     "start_time": "2022-02-23T00:46:48.941030Z"
    }
   },
   "outputs": [],
   "source": [
    "df1['yr_built'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef93056",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T00:46:48.951892Z",
     "start_time": "2022-02-23T00:46:48.951750Z"
    }
   },
   "outputs": [],
   "source": [
    "df1['yr_built'] = pd.to_datetime(df1['yr_built'], format='%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ff9f6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T00:46:48.962842Z",
     "start_time": "2022-02-23T00:46:48.962697Z"
    }
   },
   "outputs": [],
   "source": [
    "df1['yr_built'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8654dab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T00:46:48.974675Z",
     "start_time": "2022-02-23T00:46:48.974539Z"
    }
   },
   "outputs": [],
   "source": [
    "df1['yr_renovated'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8edc3b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T00:46:48.986052Z",
     "start_time": "2022-02-23T00:46:48.985910Z"
    }
   },
   "outputs": [],
   "source": [
    "df1['yr_renovated'] = df1['yr_renovated'].apply(lambda x: pd.to_datetime('1900', format='%Y') \n",
    "                          if x==0 \n",
    "                          else pd.to_datetime(x, format='%Y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c37fe7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T00:46:48.997646Z",
     "start_time": "2022-02-23T00:46:48.997507Z"
    }
   },
   "outputs": [],
   "source": [
    "df1['yr_renovated'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869c385c",
   "metadata": {},
   "source": [
    "## 1.5 Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf292084",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T00:46:49.008516Z",
     "start_time": "2022-02-23T00:46:49.008369Z"
    }
   },
   "outputs": [],
   "source": [
    "num_attributes = df1.select_dtypes(include=['int64', 'float64'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc9a241",
   "metadata": {},
   "source": [
    "### 1.5.1 Numerical Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e3dc67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T00:46:49.019181Z",
     "start_time": "2022-02-23T00:46:49.019040Z"
    }
   },
   "outputs": [],
   "source": [
    "# Central Tendency - mean, median\n",
    "mean_   = pd.DataFrame(num_attributes.apply(np.mean,   axis=0)).T\n",
    "median_ = pd.DataFrame(num_attributes.apply(np.median, axis=0)).T\n",
    "\n",
    "# Dispersion - std, min, max, range, skew, kurtosis\n",
    "rang  = pd.DataFrame(num_attributes.apply(lambda x: x.max()-x.min())).T\n",
    "skew  = pd.DataFrame(num_attributes.apply(lambda x: x.skew())).T\n",
    "kurto = pd.DataFrame(num_attributes.apply(lambda x: x.kurtosis())).T\n",
    "std   = pd.DataFrame(num_attributes.apply(np.std, axis=0)).T\n",
    "min_  = pd.DataFrame(num_attributes.apply(np.min, axis=0)).T\n",
    "max_  = pd.DataFrame(num_attributes.apply(np.max, axis=0)).T\n",
    "\n",
    "df_num_att = pd.concat([min_, max_, rang, mean_, median_, std, skew, kurto]).T.reset_index()\n",
    "df_num_att.columns = ['attributes', 'min', 'max', 'range', 'mean', 'median', 'std', 'skew', 'kurtosis']\n",
    "df_num_att"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324fb0bf",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 2.0 FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bbf4dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T00:46:49.029978Z",
     "start_time": "2022-02-23T00:46:49.029832Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df2 = df1.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5806ce5d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 2.1 Mental Map Hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2ff8b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T00:46:49.043033Z",
     "start_time": "2022-02-23T00:46:49.042896Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Image(Path(\"/home/work/Documents/repos/python_zero_ao_ds/reports/figures/mindmaphyphotesis.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9dc511",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 2.2 Hyphotesis Criation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a68318",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**H1:** Houses that have waterview, are 3 times more expansive, in average, than houses without waterview.\n",
    "\n",
    "**H2:** Houses with built year below 1955, are 50% cheaper, in average.\n",
    "\n",
    "**H3:** Houses with basement have sqf t lot that are 50% larger than the houses without basement.\n",
    "\n",
    "**H4:** The price evolution of houses YoY ( Year over Year ) is 10%.\n",
    "\n",
    "**H5:** Houses with 3 bathrooms has an growth MoM ( Month over Month ) of 15%.\n",
    "\n",
    "**H6:** Houses with 3 bedrooms has an growth MoM ( Month over Month ) of20%.\n",
    "\n",
    "**H7:** Houses built among decades of 40 and 70 are cheaper than all other houses built in other decades.\n",
    "\n",
    "**H8:** The prices increases accordingly to the newest year the house was renovated at 50% rate.\n",
    "\n",
    "**H9:** Houses with two floors are 30% more expensive than those with one.\n",
    "\n",
    "**H10:** Houses with at least two bathrooms are 10% more expensive than those with one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6e6b77",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 2.3 Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75dc1a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T00:46:49.053770Z",
     "start_time": "2022-02-23T00:46:49.053627Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df2['year']  = df2['date'].dt.year\n",
    "df2['month'] = df2['date'].dt.month\n",
    "\n",
    "# separate the houses by avverage price and zipcode\n",
    "df = df2[['zipcode', 'price']].groupby('zipcode').median().reset_index()\n",
    "df.columns = ['zipcode', 'price_median']\n",
    "\n",
    "df2 = pd.merge(df2, df, on = 'zipcode', how = 'inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ceb2ac",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 3.0 DATA FILTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e745216b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T00:46:49.065479Z",
     "start_time": "2022-02-23T00:46:49.065332Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df3 = df2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fe2170",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T00:46:49.077480Z",
     "start_time": "2022-02-23T00:46:49.077341Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df3 = df3.drop(['sqft_living15', 'sqft_lot15'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178bf2ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T00:46:49.090412Z",
     "start_time": "2022-02-23T00:46:49.090268Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df3.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac5c603",
   "metadata": {},
   "source": [
    "# 4.0 EXPLORATORY DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7909791c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T00:46:49.100714Z",
     "start_time": "2022-02-23T00:46:49.100574Z"
    }
   },
   "outputs": [],
   "source": [
    "df4 = df3.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607d5bc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T00:46:49.110923Z",
     "start_time": "2022-02-23T00:46:49.110787Z"
    }
   },
   "outputs": [],
   "source": [
    "num_attributes = df4.select_dtypes(include=['int64', 'float64'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3519e66",
   "metadata": {},
   "source": [
    "## 4.1 Univariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bd804e",
   "metadata": {},
   "source": [
    "### 4.1.1 Response Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf96842",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T00:46:49.122302Z",
     "start_time": "2022-02-23T00:46:49.122155Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.distplot(df4['price'], kde = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d3c4fc",
   "metadata": {},
   "source": [
    "### 4.1.2 Numerical Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eba9d48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T00:46:49.133159Z",
     "start_time": "2022-02-23T00:46:49.132983Z"
    }
   },
   "outputs": [],
   "source": [
    "num_attributes.hist(bins=25);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60068e9",
   "metadata": {},
   "source": [
    "## 4.2 Bivariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aaba56c",
   "metadata": {},
   "source": [
    "### H1: Houses that have waterview, are 3 times more expansive, in mean, than houses without waterview.\n",
    "### True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b84490",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T00:46:49.149237Z",
     "start_time": "2022-02-23T00:46:49.149101Z"
    }
   },
   "outputs": [],
   "source": [
    "water_price = df4[['waterfront', 'price']].groupby('waterfront').mean().reset_index()\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.bar(water_price['waterfront'], water_price['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272c25f9",
   "metadata": {},
   "source": [
    "### H2: Houses with built year below 1955, are 50% cheaper, in average.\n",
    "### FALSE: the average price of houses built before or after 1955 are approximately the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9e5a1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T00:46:49.161719Z",
     "start_time": "2022-02-23T00:46:49.161585Z"
    }
   },
   "outputs": [],
   "source": [
    "below_1955 = ['yr_built < 1955',  df4.loc[df4['yr_built']< pd.to_datetime('1955'), 'price'].mean()]\n",
    "above_1955 = ['yr_built >= 1955', df4.loc[df4['yr_built']>=pd.to_datetime('1955'), 'price'].mean()]\n",
    "                                      \n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.bar([below_1955[0], above_1955[0]], [below_1955[1], above_1955[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a06c786",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T12:54:21.137814Z",
     "start_time": "2022-02-22T12:54:21.115692Z"
    }
   },
   "source": [
    "### H3: Houses with basement have sqft lot 50% larger than the houses without basement.\n",
    "### FALSE: It is just about 20% larger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47823b45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T00:46:49.171723Z",
     "start_time": "2022-02-23T00:46:49.171514Z"
    }
   },
   "outputs": [],
   "source": [
    "with_basement    = ['with basement'   , df4.loc[df4['sqft_basement']> 0, 'sqft_lot'].mean()]\n",
    "without_basement = ['without basement', df4.loc[df4['sqft_basement']==0, 'sqft_lot'].mean()]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.bar([with_basement[0], without_basement[0]], [with_basement[1], without_basement[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e43e426",
   "metadata": {},
   "source": [
    "### H4: The price evolution of houses YoY ( Year over Year ) is 10%.\n",
    "### FALSE: the growth YoY is only about 1 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60fb46c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T00:46:49.182415Z",
     "start_time": "2022-02-23T00:46:49.182281Z"
    }
   },
   "outputs": [],
   "source": [
    "avg_year = df4[['year', 'price']].groupby('year').mean().reset_index()\n",
    "avg_year['diff(%)'] = ((avg_year['price'].diff(1))/avg_year['price'])*100\n",
    "avg_year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5221894",
   "metadata": {},
   "source": [
    "### H5: Houses with 3 bathrooms has an growth MoM ( Month over Month ) of 15%.\n",
    "### FALSE: the growth MoM is about 0%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfcf15c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T00:46:49.194374Z",
     "start_time": "2022-02-23T00:46:49.194238Z"
    }
   },
   "outputs": [],
   "source": [
    "avg_month = df4.loc[df4['bathrooms'] == 3, ['date', 'month', 'price']].sort_values('date', ascending = True)\n",
    "avg_month_14 = avg_month.loc[avg_month['date'].dt.year == 2014].groupby('month').mean().reset_index()\n",
    "avg_month_15 = avg_month.loc[avg_month['date'].dt.year == 2015].groupby('month').mean().reset_index()\n",
    "avg_mom = pd.concat([avg_month_14, avg_month_15], axis = 0)\n",
    "avg_mom['diff(%)'] = (avg_mom['price'].diff(1))/avg_mom['price']*100\n",
    "avg_mom['diff(%)'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fe1d47",
   "metadata": {},
   "source": [
    "### H6: Houses with 3 bedrooms has an growth MoM ( Month over Month ) of 20%.\n",
    "### FALSE: the growth MoM of houses with three bedrooms is about 0%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e800f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T00:46:49.206876Z",
     "start_time": "2022-02-23T00:46:49.206737Z"
    }
   },
   "outputs": [],
   "source": [
    "avg_month_bed = df4.loc[df4['bedrooms'] == 3, ['date', 'month', 'price']].sort_values('date', ascending = True)\n",
    "avg_month_bed_14 = avg_month_bed.loc[avg_month_bed['date'].dt.year == 2014].groupby('month').mean().reset_index()\n",
    "avg_month_bed_15 = avg_month_bed.loc[avg_month_bed['date'].dt.year == 2015].groupby('month').mean().reset_index()\n",
    "avg_mom_bed = pd.concat([avg_month_bed_14, avg_month_bed_15], axis = 0)\n",
    "avg_mom_bed['diff(%)'] = (avg_mom_bed['price'].diff(1))/avg_mom_bed['price']*100\n",
    "avg_mom_bed['diff(%)'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbbc0f8",
   "metadata": {},
   "source": [
    "### H7: Houses built among decades of 40 and 70 are cheaper than all other houses built in other decades.\n",
    "### TRUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5554e922",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T00:46:49.217783Z",
     "start_time": "2022-02-23T00:46:49.217629Z"
    }
   },
   "outputs": [],
   "source": [
    "avg_40_70 = df4.loc[(df4['yr_built'] >=pd.to_datetime('1940')) & \n",
    "                     (df4['yr_built']<=pd.to_datetime('1970')), \n",
    "                     ['yr_built', 'price']].groupby('yr_built').mean().reset_index()\n",
    "\n",
    "avg_40_70 = ['1940 <= yr_built <= 1970', avg_40_70['price'].mean()]\n",
    "\n",
    "avg_40 = df4.loc[df4['yr_built']<pd.to_datetime('1940'), \n",
    "                     ['yr_built', 'price']].groupby('yr_built').mean().reset_index()\n",
    "\n",
    "avg_40 = ['yr_built < 1940', avg_40['price'].mean()]\n",
    "avg_70 = df4.loc[df4['yr_built']<pd.to_datetime('1940'), \n",
    "                     ['yr_built', 'price']].groupby('yr_built').mean().reset_index()\n",
    "\n",
    "avg_70 = ['yr_built > 1970', avg_70['price'].mean()]\n",
    "\n",
    "plt.figure(figsize = (12, 8))\n",
    "plt.bar([avg_40[0], avg_40_70[0], avg_70[0]], [avg_40[1], avg_40_70[1], avg_70[1]])\n",
    "\n",
    "by_year = df4[['price', 'yr_built']].groupby('yr_built').mean().reset_index()\n",
    "plt.figure(figsize = (12, 8))\n",
    "plt.plot(by_year['yr_built'], by_year['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c2239b",
   "metadata": {},
   "source": [
    "### H8: The prices increases accordingly to the newest year the house was renovated at 10% rate.\n",
    "### FLASE: considering the year renovated, the average prices are decrising by about -8%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4626d2c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T00:46:49.228790Z",
     "start_time": "2022-02-23T00:46:49.228645Z"
    }
   },
   "outputs": [],
   "source": [
    "renovated = df4.loc[df4['yr_renovated']>pd.to_datetime('1930'), ['yr_renovated', 'price']].groupby('yr_renovated').mean().reset_index()\n",
    "renovated['diff(%)']=(renovated['price'].diff(1))/renovated['price']*100\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.lineplot(x='yr_renovated', y='price', data=renovated)\n",
    "\n",
    "renovated['diff(%)'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b4cbde",
   "metadata": {},
   "source": [
    "### H9: Houses with two floors are 30% more expensive than those with one.\n",
    "### TRUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40d6324",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T00:46:49.241246Z",
     "start_time": "2022-02-23T00:46:49.241110Z"
    }
   },
   "outputs": [],
   "source": [
    "floor_2 = df4.loc[df4['floors'] == 2, 'price'].mean()\n",
    "floor_2 = ['2 Floor', floor_2]\n",
    "\n",
    "floor_1 = df4.loc[df4['floors'] == 1, 'price'].mean()\n",
    "floor_1 = ['1 Floors', floor_1]\n",
    "\n",
    "plt.figure(figsize = (12, 8))\n",
    "plt.bar([floor_1[0], floor_2[0]], [floor_1[1], floor_2[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb63d394",
   "metadata": {},
   "source": [
    "### H10: Houses with at least two bathrooms are 10% more expensive than those with one.\n",
    "### FALSE: Houses with at least two bathrooms are about 30% more expensive than those with one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a611e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T00:46:49.251431Z",
     "start_time": "2022-02-23T00:46:49.251297Z"
    }
   },
   "outputs": [],
   "source": [
    "bath_2 = df4.loc[df4['bathrooms'] >= 2, 'price'].mean()\n",
    "bath_2 = ['2 Bathrooms', bath_2]\n",
    "\n",
    "bath_1 = df4.loc[df4['floors'] == 1, 'price'].mean()\n",
    "bath_1 = ['1 Bathrooms', bath_1]\n",
    "\n",
    "plt.figure(figsize = (12, 8))\n",
    "plt.bar([bath_1[0], bath_2[0]], [bath_1[1], bath_2[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fc7638",
   "metadata": {},
   "source": [
    "### 4.2.2 Summary of Hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0054e84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T00:46:49.261695Z",
     "start_time": "2022-02-23T00:46:49.261560Z"
    }
   },
   "outputs": [],
   "source": [
    "tab =[['Hyphotesis', 'Conclusion',  'Relevancy'],\n",
    "      ['H1',         'True',        'High'],\n",
    "      ['H2',         'False',       'Average'],\n",
    "      ['H3',         'False',       'Low'],\n",
    "      ['H4',         'False',       'High'],\n",
    "      ['H5',         'False',       'High'],\n",
    "      ['H6',         'False',       'Low'],\n",
    "      ['H7',         'True',        'Average'],\n",
    "      ['H8',         'False',       'Low'],\n",
    "      ['H9',         'True',        'Low'],\n",
    "      ['H10',        'False',       'Average']]\n",
    "\n",
    "print(tabulate(tab, headers='firstrow'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229fce08",
   "metadata": {},
   "source": [
    "# 5. SELL/ PURCHASE RECOMENDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f833a3d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T00:46:49.272751Z",
     "start_time": "2022-02-23T00:46:49.272620Z"
    }
   },
   "outputs": [],
   "source": [
    "df5 = df4.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef7edad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T00:46:49.283169Z",
     "start_time": "2022-02-23T00:46:49.283020Z"
    }
   },
   "outputs": [],
   "source": [
    "df5['status'] = df5['condition'].apply(lambda x: 'Buy' if x>2 else 'Not Buy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3056147d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T00:46:49.293351Z",
     "start_time": "2022-02-23T00:46:49.293214Z"
    }
   },
   "outputs": [],
   "source": [
    "df5['season'] = df5['date'].apply(lambda x: 'Spring' \n",
    "                                    if ((x >= pd.to_datetime('2014-03-20')) & (x < pd.to_datetime('2014-06-21')))\n",
    "                                    |  ((x >= pd.to_datetime('2015-03-20')) & (x < pd.to_datetime('2015-06-21')))\n",
    "                                    else 'Summer'\n",
    "                                    if (x >= pd.to_datetime('2014-06-21')) & (x < pd.to_datetime('2014-09-22'))\n",
    "                                    else 'Fall'\n",
    "                                    if (x >= pd.to_datetime('2014-09-22')) & (x < pd.to_datetime('2014-12-21'))\n",
    "                                    else 'Winter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158ede2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T00:46:49.303519Z",
     "start_time": "2022-02-23T00:46:49.303395Z"
    }
   },
   "outputs": [],
   "source": [
    "df5['sell_price'] = df5[['price', 'price_median', 'status']].apply(lambda x: \n",
    "                                   x['price']*1.3 if (x['price'] <  x['price_median']) & (x['status'] == 'Buy')\n",
    "                              else x['price']*1.1 if (x['price'] >= x['price_median']) & (x['status'] == 'Buy') \n",
    "                              else 0, axis = 1)\n",
    "\n",
    "df5['profit'] = df5[['sell_price', 'price']].apply(lambda x: \n",
    "                                            (x['sell_price'] - x['price']) if x['sell_price'] != 0\n",
    "                                       else 0, axis = 1)\n",
    "\n",
    "\n",
    "#for i in range(len(df5)):\n",
    "#    if (df5.loc[i, 'status']=='Buy'):\n",
    "#        if(df5.loc[i, 'price'] < df5.loc[i, 'price_median']):\n",
    "#            df5.loc[i, 'sell_price'] = df5.loc[i, 'price']*1.3\n",
    "#        else:\n",
    "#            df5.loc[i, 'sell_price'] = df5.loc[i, 'price']*1.1\n",
    "#        df5.loc[i, 'profit']     = df5.loc[i, 'sell_price'] - df5.loc[i, 'price']\n",
    "#    else:\n",
    "#        df5.loc[i, 'sell_price'] = 0\n",
    "#        df5.loc[i, 'profit']     = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd05f542",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T00:46:49.313138Z",
     "start_time": "2022-02-23T00:46:49.313004Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "purchase_sell_rec = df5.loc[df5['status'] == 'Buy'][['id', 'zipcode', 'price_median', 'price', 'sell_price', 'profit', 'season']]\n",
    "purchase_sell_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26460be0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T00:45:08.209329Z",
     "start_time": "2022-02-23T00:45:05.037296Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'purchase_sell_rec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpurchase_sell_rec\u001b[49m[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msell_price\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprofit\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39msum()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'purchase_sell_rec' is not defined"
     ]
    }
   ],
   "source": [
    "purchase_sell_rec[['price', 'sell_price', 'profit']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "e9ec8c16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T17:40:31.370921Z",
     "start_time": "2022-02-22T17:40:30.902255Z"
    }
   },
   "outputs": [],
   "source": [
    "#define interactive buttons\n",
    "price_limit = widgets.IntSlider(\n",
    "    value = int(df5['price'].mean()),\n",
    "    min = int(df5['price'].min()),\n",
    "    max = int(df5['price'].max()),\n",
    "    step = 1,\n",
    "    description = 'Maximum Price',\n",
    "    disable = False,\n",
    "    style = {'description_width': 'initial'})\n",
    "\n",
    "living_limit = widgets.IntSlider(\n",
    "    value = int(df5['sqft_living'].mean()),\n",
    "    min = int(df5['sqft_living'].min()),\n",
    "    max = int(df5['sqft_living'].max()),\n",
    "    step = 1,\n",
    "    description = 'Minimum Living Room Size',\n",
    "    disable = False,\n",
    "    style = {'description_width': 'initial'})\n",
    "\n",
    "bathroom_limit = widgets.IntSlider(\n",
    "    value = int(df5['bathrooms'].mean()),\n",
    "    min = int(df5['bathrooms'].min()),\n",
    "    max = int(df5['bathrooms'].max()),\n",
    "    step = 1,\n",
    "    description = 'Minimum Bathrooms Values',\n",
    "    disable = False,\n",
    "    style = {'description_width': 'initial'})\n",
    "\n",
    "basement_limit = widgets.IntSlider(\n",
    "    value = df5['sqft_basement'].mean(),\n",
    "    min = df5['sqft_basement'].min(),\n",
    "    max = df5['sqft_basement'].max(),\n",
    "    step = 1,\n",
    "    description = 'Maximum Basement Size',\n",
    "    disable = False,\n",
    "    style = {'description_width': 'initial'})\n",
    "\n",
    "condition_limit = widgets.IntSlider(\n",
    "    value = df5['condition'].mean(),\n",
    "    min = df5['condition'].min(),\n",
    "    max = df5['condition'].max(),\n",
    "    step = 1,\n",
    "    description = 'House Minimum Condition',\n",
    "    disable = False,\n",
    "    style = {'description_width': 'initial'})\n",
    "\n",
    "yrbuilt_limit = widgets.IntSlider(\n",
    "    value = df5['yr_built'].dt.year.mean(),\n",
    "    min = df5['yr_built'].dt.year.min(),\n",
    "    max = df5['yr_built'].dt.year.max(),\n",
    "    step = 1,\n",
    "    description = 'Built Since Year',\n",
    "    disable = False,\n",
    "    style = {'description_width': 'initial'})\n",
    "\n",
    "waterfront_limit = widgets.Checkbox(\n",
    "    value = False,\n",
    "    description = 'Only waterfront',\n",
    "    disable = False,\n",
    "    indent = False)\n",
    "\n",
    "def update_map(df, price_limit, living_limit, bathroom_limit, basement_limit, condition_limit, yrbuilt_limit, waterfront_limit): #passa como argumento o df5set e o critÃ©rio de seleÃ§Ã£o\n",
    "    #filter df5\n",
    "    if(waterfront_limit):\n",
    "        houses = df[(df['price'] < price_limit) &\n",
    "                   (df['sqft_living'] > living_limit) &\n",
    "                   (df['bathrooms'] >= bathroom_limit) &\n",
    "                   (df['sqft_basement'] < basement_limit) &\n",
    "                   (df['condition'] >= condition_limit) &\n",
    "                   (df['yr_built'].dt.year >= yrbuilt_limit) &\n",
    "                   (df['waterfront'] == waterfront_limit)][['id', 'lat', 'long', 'price', 'status']].copy()\n",
    "    elif(waterfront_limit == False):\n",
    "        houses = df[(df['price'] < price_limit) &\n",
    "                   (df['sqft_living'] > living_limit) &\n",
    "                   (df['bathrooms'] >= bathroom_limit) &\n",
    "                   (df['sqft_basement'] < basement_limit) &\n",
    "                   (df['condition'] >= condition_limit) &\n",
    "                   (df['yr_built'].dt.year >= yrbuilt_limit)][['id', 'lat', 'long', 'price', 'status']].copy()\n",
    "    \n",
    "    #plot map\n",
    "    fig = px.scatter_mapbox(houses,\n",
    "                           lat = 'lat',\n",
    "                           lon = 'long',\n",
    "                           color = 'status',\n",
    "                           size = 'price',\n",
    "                           color_continuous_scale = px.colors.cyclical.IceFire,\n",
    "                           size_max = 15,\n",
    "                           zoom = 9)\n",
    "    \n",
    "    fig.update_layout(mapbox_style = 'open-street-map')\n",
    "    fig.update_layout(height = 600, margin = {'r':0, 'l':0, 't':0 , 'b':0})\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "44b644f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T17:40:34.689767Z",
     "start_time": "2022-02-22T17:40:33.876260Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "721a1c2a76f040178a61162ab0da9de9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=540529, description='Maximum Price', max=7700000, min=75000, style=Slideâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "widgets.interactive(update_map, df = fixed(df5), \n",
    "                    price_limit = price_limit,\n",
    "                    living_limit = living_limit,\n",
    "                    bathroom_limit = bathroom_limit,\n",
    "                   basement_limit = basement_limit,\n",
    "                   condition_limit = condition_limit,\n",
    "                   yrbuilt_limit = yrbuilt_limit,\n",
    "                   waterfront_limit = waterfront_limit) # fixed mantÃ©m o dado ao se alterar os valores do filtro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64164f93",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 6.0 DEPLOY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38290258",
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import ipywidgets     as widgets\n",
    "import seaborn        as sns\n",
    "import plotly.express as px\n",
    "import streamlit as st\n",
    "\n",
    "import pandas         as pd\n",
    "import numpy          as np\n",
    "\n",
    "from matplotlib       import pyplot    as plt\n",
    "\n",
    "from ipywidgets       import fixed,interact, interactive, fixed, interact_manual\n",
    "from geopy.geocoders  import Nominatim\n",
    "from tabulate         import tabulate\n",
    "from matplotlib       import gridspec\n",
    "from pathlib          import Path\n",
    "from folium.plugins   import MarkerCluster\n",
    "from streamlit_folium import folium_static\n",
    "from datetime         import datetime\n",
    "\n",
    "import geopandas\n",
    "import folium\n",
    "\n",
    "st.set_page_config(layout='wide')\n",
    "f_data = st.sidebar.checkbox('Show Portfolio Page')\n",
    "\n",
    "@st.cache(allow_output_mutation=True)\n",
    "def get_data(path):\n",
    "    data = pd.read_csv(path)\n",
    "\n",
    "    return data\n",
    "\n",
    "@st.cache(allow_output_mutation = True)\n",
    "def get_geofile(url):\n",
    "    geofile = geopandas.read_file(url)\n",
    "\n",
    "    return geofile\n",
    "\n",
    "def set_feature(data):\n",
    "    data['price_m2'] = data['price']/data['sqft_lot']\n",
    "\n",
    "    return data\n",
    "\n",
    "if f_data:\n",
    "    def overview_data(data):\n",
    "        # ==============\n",
    "        # Data Overview\n",
    "        # ==============\n",
    "        st.title('HOUSES CO')\n",
    "        st.title('Data Overview')\n",
    "        \n",
    "        f_zipcode = st.sidebar.multiselect('Enter zipcode', data['zipcode'].unique())\n",
    "        f_attributes = st.sidebar.multiselect('Enter columns', data.columns)\n",
    "\n",
    "        # Filter overview table\n",
    "        if   (f_zipcode != []) & (f_attributes != []):\n",
    "            ov_data = data.loc[data['zipcode'].isin(f_zipcode), f_attributes]\n",
    "        elif (f_zipcode != []) & (f_attributes == []):\n",
    "            ov_data = data.loc[data['zipcode'].isin(f_zipcode), :]\n",
    "        elif (f_zipcode == []) & (f_attributes != []):\n",
    "            ov_data = data.loc[:, f_attributes]\n",
    "        else:\n",
    "            ov_data = data.copy()\n",
    "        st.dataframe(ov_data)\n",
    "        \n",
    "        c1, c2 = st.columns((1, 1))\n",
    "            # Average metrics\n",
    "            \n",
    "        if (f_zipcode != []):\n",
    "            avg_data = data.loc[data['zipcode'].isin(f_zipcode), :]\n",
    "        else:\n",
    "            avg_data = data.copy()\n",
    "            \n",
    "        avg_data['price_m2'] = data['price_m2']\n",
    "        df1 = avg_data[['id', 'zipcode']].groupby('zipcode').count().reset_index()\n",
    "        df2 = avg_data[['price', 'zipcode']].groupby('zipcode').mean().reset_index()\n",
    "        df3 = avg_data[['sqft_living', 'zipcode']].groupby('zipcode').mean().reset_index()\n",
    "        df4 = avg_data[['price_m2', 'zipcode']].groupby('zipcode').count().reset_index()\n",
    "            \n",
    "        m1 = pd.merge(df1, df2, on='zipcode', how='inner')\n",
    "        m2 = pd.merge(m1,  df3, on='zipcode', how='inner')\n",
    "        df = pd.merge(m2,  df4, on='zipcode', how='inner')\n",
    "        df.columns = ['zipcode', 'total_houses', 'price', 'sqft_living', 'price/m2']\n",
    "        \n",
    "        c1.header('Average Values')\n",
    "        c1.dataframe(df, height=600)\n",
    "        \n",
    "            # Statistic Descriptive\n",
    "        if (f_attributes != []):\n",
    "            num_attributes = data[f_attributes].select_dtypes(include=['int64', 'float64'])\n",
    "        else:\n",
    "            num_attributes = data.select_dtypes(include=['int64', 'float64'])\n",
    "            \n",
    "        media   = pd.DataFrame(num_attributes.apply(np.mean))\n",
    "        mediana = pd.DataFrame(num_attributes.apply(np.median))\n",
    "        std     = pd.DataFrame(num_attributes.apply(np.std))\n",
    "        max_    = pd.DataFrame(num_attributes.apply(np.max))\n",
    "        min_    = pd.DataFrame(num_attributes.apply(np.min))\n",
    "        df1     = pd.concat([max_, min_, media, mediana, std], axis=1).reset_index()\n",
    "        df1.columns = ['attributes', 'max', 'min', 'mean', 'median', 'std']\n",
    "        \n",
    "        c2.header('Descriptive Analysis')\n",
    "        c2.dataframe(df1, height=600)\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def portfolio_density(data, geofile):\n",
    "        # =======================\n",
    "        # Densidade de PortfÃ³lio\n",
    "        # =======================\n",
    "        st.title('Region Overview')\n",
    "        \n",
    "        c1, c2 = st.columns((1, 1))\n",
    "        \n",
    "        c1.header('Portfolio Density')\n",
    "        \n",
    "        df = data\n",
    "        \n",
    "        # Base Map - Folium\n",
    "        density_map = folium.Map(location=[data['lat'].mean(), data['long'].mean()], default_zoom_start=15)\n",
    "        marker_cluster = MarkerCluster().add_to(density_map)\n",
    "        \n",
    "        for name, row in df.iterrows():\n",
    "            folium.Marker([row['lat'], row['long']], popup='Sold R${0} on: {1}. Features: {2} sqft, {3} bedrooms, {4} bathrooms, year built: {5}'\n",
    "                      .format(row['price'],\n",
    "                              row['date'],\n",
    "                              row['sqft_living'],\n",
    "                              row['bedrooms'],\n",
    "                              row['bathrooms'],\n",
    "                              row['yr_built'])).add_to(marker_cluster)\n",
    "        with c1:\n",
    "            folium_static(density_map)\n",
    "            \n",
    "        # Region Price Map\n",
    "        c2.header('Price Density')\n",
    "        df = data[['price', 'zipcode']].groupby('zipcode').mean().reset_index()\n",
    "        df.columns = ['ZIP', 'PRICE']\n",
    "\n",
    "        geofile = geofile[geofile['ZIP'].isin(df['ZIP'].tolist())]\n",
    "        region_price_map = folium.Map(location=[data['lat'].mean(),\n",
    "                                            data['long'].mean()],\n",
    "                                  default_zoom_start=15)\n",
    "        region_price_map.choropleth(data=df,\n",
    "                                geo_data=geofile,\n",
    "                                columns=['ZIP', 'PRICE'],\n",
    "                                key_on='feature.properties.ZIP',\n",
    "                                fill_color='YlOrRd',\n",
    "                                fill_opacity=0.7,\n",
    "                                line_opacity=0.2,\n",
    "                                legend_name='AVG PRICE')\n",
    "        with c2:\n",
    "            folium_static(region_price_map)\n",
    "            \n",
    "        return None\n",
    "    \n",
    "    def commercial_distribution(data):\n",
    "        # ==================================================\n",
    "        # DistribuiÃ§Ã£o dos imÃ³veis por categorias comerciais\n",
    "        # ==================================================\n",
    "        st.sidebar.title('Coomercial Options')\n",
    "        \n",
    "        st.title('Commercial Attributes')\n",
    "        \n",
    "        # Average Price per Year\n",
    "        data['date'] = pd.to_datetime(data['date']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "        min_year_built = int(data['yr_built'].min())\n",
    "        max_year_built = int(data['yr_built'].max())\n",
    "        st.sidebar.subheader('Select Max Year Built')\n",
    "        f_year_built = st.sidebar.slider('Year Built', min_year_built,\n",
    "                                     max_year_built,\n",
    "                                     max_year_built)\n",
    "        st.header('Average Price per Year Built')\n",
    "        \n",
    "        df = data.loc[data['yr_built'] < f_year_built]\n",
    "        df = df[['yr_built', 'price']].groupby('yr_built').mean().reset_index()\n",
    "\n",
    "        fig = px.line(df, x='yr_built', y='price')\n",
    "        st.plotly_chart(fig, use_container_width=True)\n",
    "        \n",
    "        # Average Price per Day\n",
    "        st.header('Average Price per Day')\n",
    "        st.sidebar.subheader('Select Max Date')\n",
    "\n",
    "        min_date = datetime.strptime(data['date'].min(), '%Y-%m-%d')\n",
    "        max_date = datetime.strptime(data['date'].max(), '%Y-%m-%d')\n",
    "\n",
    "        f_date = st.sidebar.slider('Date', min_date, max_date, max_date)\n",
    "    \n",
    "        data['date'] = pd.to_datetime(data['date'])\n",
    "        df = data.loc[data['date'] < f_date]\n",
    "        df = df[['date', 'price']].groupby('date').mean().reset_index()\n",
    "\n",
    "        fig = px.line(df, x='date', y='price')\n",
    "        st.plotly_chart(fig, use_container_width=True)\n",
    "        \n",
    "        # Histograma\n",
    "        st.header('Price Distribution')\n",
    "        st.sidebar.subheader('Select Max Price')\n",
    "\n",
    "        min_price = int(data['price'].min())\n",
    "        max_price = int(data['price'].max())\n",
    "        avg_price = int(data['price'].mean())\n",
    "        f_price = st.sidebar.slider('Price', min_price, max_price, max_price)\n",
    "        df = data.loc[data['price'] < f_price]\n",
    "\n",
    "        fig = px.histogram(df, x='price', nbins=50)\n",
    "        st.plotly_chart(fig, use_container_width=True)\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def attributes_distribution(data):\n",
    "        # ===============================================\n",
    "        # DistribuiÃ§Ã£o dos imoveis por categorias fÃ­sicas\n",
    "        # ===============================================\n",
    "        st.sidebar.title('Attributes Options')\n",
    "        \n",
    "        st.title('House Attributes')\n",
    "\n",
    "        f_bedrooms  = st.sidebar.selectbox('Max number of bedrooms',  sorted(set(data['bedrooms'].unique())))\n",
    "        f_bathrooms = st.sidebar.selectbox('Max number of bathrooms', sorted(set(data['bathrooms'].unique())))\n",
    "        \n",
    "        c1, c2 = st.columns(2)\n",
    "        \n",
    "        # House per bedroms\n",
    "        c1.header('Houses per bedrooms')\n",
    "        df = data[data['bedrooms'] < f_bedrooms]\n",
    "        fig = px.histogram(df, x='bedrooms', nbins=19)\n",
    "        c1.plotly_chart(fig, use_container_width=True)\n",
    "        \n",
    "        # House per bathrooms\n",
    "        c2.header('Houses per bathrooms')\n",
    "        df = data[data['bathrooms'] < f_bathrooms]\n",
    "        fig = px.histogram(df, x='bathrooms', nbins=19)\n",
    "        c2.plotly_chart(fig, use_container_width=True)\n",
    "        \n",
    "        # filters\n",
    "        f_floors = st.sidebar.selectbox('Max number of floor', sorted(set(data['floors'].unique())))\n",
    "        f_waterview = st.sidebar.checkbox('Water View')\n",
    "        \n",
    "        c1, c2 = st.columns(2)\n",
    "        \n",
    "        # House per floors\n",
    "        c1.header('House per floors')\n",
    "        df = data[data['floors'] < f_floors]\n",
    "        fig = px.histogram(df, x='floors', nbins=19)\n",
    "        c1.plotly_chart(fig, use_container_width=True)\n",
    "        \n",
    "        # House per water view\n",
    "        c2.header('Water View')\n",
    "        if f_waterview:\n",
    "            df = data[data['waterfront'] == 1]\n",
    "        else:\n",
    "            df = data.copy()\n",
    "            \n",
    "        fig = px.histogram(df, x='waterfront', nbins=10)\n",
    "        \n",
    "        c2.plotly_chart(fig, use_container_width=True)\n",
    "        \n",
    "        return None\n",
    "            \n",
    "######################################################################################################\t\t\n",
    "######################################################################################################\t\t\n",
    "######################################################################################################\n",
    "\n",
    "else:\n",
    "    \n",
    "    def sell_attributes(data):\n",
    "        \n",
    "        st.title('HOUSES CO')\n",
    "        st.title('Purchase/ Sell Table')\n",
    "        \n",
    "        st.sidebar.title('Table Filter')\n",
    "        \n",
    "        f_zipcode = st.sidebar.multiselect('Enter zipcode', data['zipcode'].unique())\n",
    "        \n",
    "        if (f_zipcode != []):\n",
    "            data = data.loc[data['zipcode'].isin(f_zipcode)]\n",
    "        else:\n",
    "            data = data.copy()\n",
    "               \n",
    "        df = data[['zipcode', 'price']].groupby('zipcode').median().reset_index()\n",
    "        \n",
    "        df.columns = ['zipcode', 'price_median']\n",
    "\n",
    "        data = pd.merge(data, df, on = 'zipcode', how = 'inner')\n",
    "        \n",
    "        data['status'] = data['condition'].apply(lambda x: 'Buy' if x>2 else 'Not Buy')\n",
    "        \n",
    "        data['date'] = pd.to_datetime(data['date'])\n",
    "        \n",
    "        data['season'] = data['date'].apply(lambda x: 'Spring' \n",
    "                                    if ((x >= pd.to_datetime('2014-03-20')) & (x < pd.to_datetime('2014-06-21')))\n",
    "                                    |  ((x >= pd.to_datetime('2015-03-20')) & (x < pd.to_datetime('2015-06-21')))\n",
    "                                    else 'Summer'\n",
    "                                    if (x >= pd.to_datetime('2014-06-21')) & (x < pd.to_datetime('2014-09-22'))\n",
    "                                    else 'Fall'\n",
    "                                    if (x >= pd.to_datetime('2014-09-22')) & (x < pd.to_datetime('2014-12-21'))\n",
    "                                    else 'Winter')   \n",
    "        \n",
    "        data['sell_price'] = data[['price', 'price_median', 'status']].apply(lambda x: \n",
    "                                   x['price']*1.3 if (x['price'] <  x['price_median']) & (x['status'] == 'Buy')\n",
    "                              else x['price']*1.1 if (x['price'] >= x['price_median']) & (x['status'] == 'Buy') \n",
    "                              else 0, axis = 1)\n",
    "\n",
    "        data['profit'] = data[['sell_price', 'price']].apply(lambda x: \n",
    "                                            (x['sell_price'] - x['price']) if x['sell_price'] != 0\n",
    "                                       else 0, axis = 1)\n",
    "        \n",
    "        purchase_sell_rec = data.loc[data['status'] == 'Buy'][['id', 'zipcode', 'price_median', 'price', 'sell_price', 'profit', 'season']]\n",
    "        \n",
    "        st.dataframe(purchase_sell_rec)\n",
    "        \n",
    "        return None\n",
    "\n",
    "    def update_map(data): \n",
    "        #filter data\n",
    "        st.title('Map Recomendations')\n",
    "        \n",
    "        st.sidebar.title('Map Filter')\n",
    "        \n",
    "        min_price = int(data['price'].min())\n",
    "        max_price = int(data['price'].max())\n",
    "        avg_price = int(data['price'].mean())\n",
    "        price_limit = st.sidebar.slider('Price', min_price, max_price, max_price)\n",
    "        \n",
    "        value = int(data['sqft_living'].mean())\n",
    "        min_ = int(data['sqft_living'].min())\n",
    "        max_ = int(data['sqft_living'].max())\n",
    "        living_limit = st.sidebar.slider('Minimum Living Room Size', min_, max_, min_)\n",
    "    \n",
    "        value = int(data['bathrooms'].mean())\n",
    "        min_ = int(data['bathrooms'].min())\n",
    "        max_ = int(data['bathrooms'].max())\n",
    "        bathroom_limit = st.sidebar.slider('Minimum Bathrooms Values', min_, max_, min_)\n",
    "       \n",
    "        value = int(data['yr_built'].mean())\n",
    "        min_ =  int(data['yr_built'].min())\n",
    "        max_ =  int(data['yr_built'].max())\n",
    "        yrbuilt_limit  = st.sidebar.slider('Built Since Year', min_, max_, min_)#value)\n",
    "       \n",
    "        waterfront_limit = st.sidebar.checkbox('Only waterfront', value=False, disabled=False)\n",
    "\n",
    "        data['status'] = data['condition'].apply(lambda x: 'Buy' if x>2 else 'Not Buy')\n",
    "        \n",
    "        if(waterfront_limit):\n",
    "            houses = data[(data['price'] < price_limit) &\n",
    "                       (data['sqft_living'] > living_limit) &\n",
    "                       (data['bathrooms'] >= bathroom_limit) &\n",
    "                       (data['yr_built'] >= yrbuilt_limit) &\n",
    "                       (data['waterfront'] == waterfront_limit)][['id', 'lat', 'long', 'price', 'status']].copy()\n",
    "        elif(waterfront_limit == False):\n",
    "            houses = data[(data['price'] < price_limit) &\n",
    "                       (data['sqft_living'] > living_limit) &\n",
    "                       (data['bathrooms'] >= bathroom_limit) &\n",
    "                       (data['yr_built'] >= yrbuilt_limit)][['id', 'lat', 'long', 'price', 'status']].copy()\n",
    "        \n",
    "        #plot map\n",
    "        fig = px.scatter_mapbox(houses,\n",
    "                               lat = 'lat',\n",
    "                               lon = 'long',\n",
    "                               color = 'status',\n",
    "                               size = 'price',\n",
    "                               color_continuous_scale = px.colors.cyclical.IceFire,\n",
    "                               size_max = 15,\n",
    "                               zoom = 9)\n",
    "        \n",
    "        fig.update_layout(mapbox_style = 'open-street-map')\n",
    "        fig.update_layout(height = 600, margin = {'r':0, 'l':0, 't':0 , 'b':0})\n",
    "        st.plotly_chart(fig)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    path = 'data/raw/kc_house_data.csv'\n",
    "        \n",
    "    data = get_data(path)\n",
    "        \n",
    "    if f_data:\n",
    "        \n",
    "        url = 'https://opendata.arcgis.com/datasets/83fc2e72903343aabff6de8cb445b81c_2.geojson'\n",
    "        \n",
    "        geofile = get_geofile( url )\n",
    "        \n",
    "        data = set_feature(data)\n",
    "        \n",
    "        overview_data(data)\n",
    "        \n",
    "        portfolio_density(data, geofile)\n",
    "    \n",
    "        commercial_distribution(data)\n",
    "    \n",
    "        attributes_distribution(data)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        sell_attributes(data)\n",
    "        \n",
    "        update_map(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonzeroaods",
   "language": "python",
   "name": "pythonzeroaods"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
